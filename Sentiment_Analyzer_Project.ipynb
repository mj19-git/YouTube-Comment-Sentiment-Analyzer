{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E3JdyZSkvWVF"
   },
   "source": [
    "#Problem Statement\n",
    "\n",
    "We have a huge number of comments from YouTube for a latest trailer from a worldwide production house, you as an AI\n",
    "service provider are supposed to analyse all the comments on that trailer, get the sentiment and the score, and give\n",
    "a consolidated report for that trailer about how it might perform on the box office.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "62iGRxQovk6z",
    "outputId": "e7133a9c-2065-433b-85f1-3a5061637af3"
   },
   "outputs": [],
   "source": [
    "#Tools and high level steps that will be used in the project.\n",
    "\"\"\"\n",
    "1. Get your comments from the Youtube trailer. One option would manually getting the comments, get them directly from the API, you can save them in a file and\n",
    "load it in your colab.\n",
    "\n",
    "2.Setup your colab to do the job for you, you will need to install the required libraries.\n",
    "PyTorch - torch\n",
    "HuggingFace - transformers\n",
    "NLTK - nltk\n",
    "VADER - sentiment.vader\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "7BDH1FY3vq_A",
    "outputId": "7ec060ea-c5d5-4506-ab74-bff6d60cc385"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "STEPS :-\n",
    "\n",
    "1.Do all the necessary imports\n",
    "2.create a function for removing stop words\n",
    "3.create a function to calculate the sentiment score and the sentiment(positive/negative)\n",
    "4.Loop through the Comments that you will get from your input excel file\n",
    "4.5 Seggreate the words into positive and negative, so you can make a word cloud at the end\n",
    "5.Calculate all the sentiments in loop and return only one final result\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q0mpiIgDzMh6",
    "outputId": "78d22909-2312-486c-9882-6b154d7084ef"
   },
   "outputs": [],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KKCUfBXSOYvG",
    "outputId": "55bbf9ab-53f0-4e1b-be90-722323a29dde"
   },
   "outputs": [],
   "source": [
    "!pip install transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9q_zr0QGOqoe",
    "outputId": "666db61d-f89b-4c65-f291-cebd4fcf89fe"
   },
   "outputs": [],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S1q65seuOzWc",
    "outputId": "d8f52aa1-8418-44f4-c979-e432ce75d888"
   },
   "outputs": [],
   "source": [
    "!pip install vaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vOhCTdr6PLjW"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_excel(\"/content/SnowWhite Comments.xlsx\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lPB0ZDmgLisN"
   },
   "outputs": [],
   "source": [
    "comments = []\n",
    "comments = df[\"Comments\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aE_uYy-xLkpY",
    "outputId": "d6e12fcd-46bd-4b36-dbd4-3eb90d9bb28f"
   },
   "outputs": [],
   "source": [
    "for comment in comments:\n",
    "  print(comment)\n",
    "  print(\"===\")\n",
    "# print(comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X05JHX1MMMe4",
    "outputId": "c1e1483e-38cd-4469-8742-ae6cd81ac402"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "nltk.download(\"vader_lexicon\")\n",
    "\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "#stopwords - WOrds that help make up a sentence but don't have their own meaning\n",
    "#it, they, them, what, am, I\n",
    "comment_score1 = sia.polarity_scores(\"I am Very happy with this movie.\")\n",
    "print(comment_score1)\n",
    "\n",
    "\n",
    "comment_score2 = sia.polarity_scores(\"I am extremely sad today.\")\n",
    "print(comment_score2)\n",
    "\n",
    "\n",
    "comment_score3 = sia.polarity_scores(\"This is an amazing and outstanding movie.\")\n",
    "print(comment_score3)\n",
    "\n",
    "\n",
    "comment_score4 = sia.polarity_scores(\"The first part was amazing and outstanding, but this part sucks.\")\n",
    "print(comment_score4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZTP7LVLZqtYB",
    "outputId": "f58a7267-380b-4269-a74b-97065d1b5a65"
   },
   "outputs": [],
   "source": [
    "#for classifying my comments into positive and negative, I will be using an AI model\n",
    "#from HuggingFace to get the score of the sentence, we will go with nltk/vader sentiment.\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download(\"stopwords\")\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "nltk.download(\"punkt_tab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qrk5oc-S3jEq",
    "outputId": "79634f6c-d00b-4375-8299-12b66b874aad"
   },
   "outputs": [],
   "source": [
    "sentence = \"Today is a very warm and sunny day, I would like to go out and play football with my friends\"\n",
    "tokenized_comment = word_tokenize(sentence)\n",
    "print(\"Tokenized comment: \",tokenized_comment)\n",
    "\n",
    "processed_comment = [word for word in tokenized_comment if word.lower() not in stop_words]\n",
    "print(processed_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fhl-0zlm5G5Q"
   },
   "outputs": [],
   "source": [
    "def remove_stopwords(raw_comment):\n",
    "  tokenized_comment = word_tokenize(raw_comment)\n",
    "  processed_comment = [word for word in tokenized_comment if word.lower() not in stop_words]\n",
    "  return ' '.join(processed_comment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "imlTbZDK5esD",
    "outputId": "ad41e5b5-ed03-4e55-cc5a-4e9b7e7b8d1b"
   },
   "outputs": [],
   "source": [
    "result = remove_stopwords( \"Today is a very warm and sunny day, I would like to go out and play football with my friends\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ABGCST2O8Qou",
    "outputId": "0e7517ab-d1e3-4f1d-a210-5db40bfc33fe"
   },
   "outputs": [],
   "source": [
    "#whatever you are trying to return - for - condition\n",
    "fruits = [\"Banana\", \"Apple\",\"Fig\",\"Orange\" ]\n",
    "result = [fruit for fruit in fruits if len(fruit) < 4]\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4eBDcWsezewb"
   },
   "source": [
    "\n",
    "# Using Model :-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e_I5F_yt5oV6",
    "outputId": "51fe10a7-4a05-41e9-d600-15a50be99882"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "#from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z11iWSJAxAeR"
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286,
     "referenced_widgets": [
      "f7d2ac4609a044c69b9aade4b6a7bbcc",
      "2966fceb920a45419f25a3874a9717f3",
      "6e63ea9f156349b6bbb229bc0ea92a53",
      "b73d50f1d87b480a9e31eea1301f2b4c",
      "d234c6d5629e4b30aa35e17fae36dbde",
      "6efd6cb9d3c242b99f94b288928b370a",
      "80b0b39cb6e14381ace2aa3f73b2d98a",
      "444397157bd746ea80198f26556b90d3",
      "4b531892f05b4cb88cec5145ee41acbf",
      "f741755748b34d5baaf8226d40bb90f1",
      "03c7230bd7e8484bac3cf403da256529",
      "be5435fe38a840c3b7b57e1e6e6a284f",
      "d30e9433ebca4abea44c8fe5e8a84e48",
      "0cb07f167693485c8d6d8887ffd4adec",
      "b7fb7955a7b740a6a39fb6cfe3f1fad5",
      "89baadb953474ef69a9c60114b5db734",
      "3370ebffbb0b4bbb9d2e026c6799f143",
      "fc93021f95124c32aa67cd54a0a9784f",
      "5842f8b9ed674a3f8d382e0b99757b2a",
      "1f8424fd3e5e41918a0f5765807c61cb",
      "79b7fdad95ac46a3887a201595cdc3ff",
      "55be04d385514c6f8e35c53b218f388f",
      "0552d8559c0c48a6b5063c9d00c0ddba",
      "9e3f20f8f37448c19c139680f9625971",
      "3ce5173653d74f68be2b3cdf5b9952d5",
      "3b1155a064b54451881f21d7ea0efdb1",
      "11f2a1c398004d58b1a676fb13bd9f79",
      "238a24da8f0f49f8b4959e89cb4a2511",
      "a5a0e5dbb53447f7abc90f0e35b81001",
      "3409e08f5fb5490a84391242846c31ce",
      "82cfe3f20150437abc5731b30d4d6e0a",
      "046218f8938f47a9ba34ebbc4c42699a",
      "ab3e56d76d7644d48a66474bfc643919",
      "4871671c23b54c5d87fe6f1962a0a764",
      "53082b43e6bd4ef8a580d51e82734478",
      "97fef7b18971442f8b5e3b462ce72263",
      "fc0ee9b4ebdd47c8a25d1826783fffe4",
      "9d029f6294744c95bbf755f152b20772",
      "bd65b378750c4e51baf28fc52d7f6175",
      "1efe0eac9e244f62a99e55172f2a758b",
      "b073a9453c44494f8d6abea4cb79df90",
      "a715ebeaf769441da175457aa216247a",
      "8235622f5913479da7704e2fcd4fb520",
      "0650c476a272436785fc5e7dab530e57"
     ]
    },
    "id": "2J8n6dHnzSya",
    "outputId": "8b803ede-38db-4d8d-be9a-2cf71c5d8570"
   },
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "stop_words = stop_words = set(stopwords.words('english'))\n",
    "classifier = pipeline(\"sentiment-analysis\", model=\"distilbert/distilbert-base-uncased-finetuned-sst-2-english\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ohfIDxY90acj"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_excel(\"/content/SnowWhite Comments.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eV-V4gCv0nrE"
   },
   "outputs": [],
   "source": [
    "comments = []\n",
    "comments = df[\"Comments\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2tj1DEsD1Mbl"
   },
   "outputs": [],
   "source": [
    "def remove_stopwords(raw_comment):\n",
    "  tokenized_comment = word_tokenize(raw_comment)\n",
    "  processed_comment = [word for word in tokenized_comment if word.lower() not in stop_words]\n",
    "  return ' '.join(processed_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lhMV7RQz1WEz"
   },
   "outputs": [],
   "source": [
    "def get_comment_sentiment_details(raw_comment):\n",
    "  processed_comment = remove_stopwords(raw_comment)\n",
    "\n",
    "  words = processed_comment.split()\n",
    "  positive_words = \"\"\n",
    "  negative_words = \"\"\n",
    "  comment_sentiment = \"\" #Either POSITIVE or NEGATIVE\n",
    "\n",
    "  sentence_score_temp = sia.polarity_scores(processed_comment)\n",
    "\n",
    "  abs_sentence_score = abs(sentence_score_temp['compound']) #absolute means if I have -3.4 -> 3.4\n",
    "  sentiment_label = classifier(processed_comment)\n",
    "  comment_sentiment = sentiment_label[0]['label']\n",
    "\n",
    "  if abs_sentence_score == 0:\n",
    "    comment_sentiment = \"NEUTRAL\"\n",
    "\n",
    "  if comment_sentiment == \"NEGATIVE\":\n",
    "    sentence_score = abs_sentence_score * -1\n",
    "    for word in words:\n",
    "      word_sentiment = sia.polarity_scores(word)\n",
    "      if word_sentiment['compound'] < 0:\n",
    "        negative_words += word + \" \"\n",
    "\n",
    "  elif comment_sentiment == \"POSITIVE\":\n",
    "    sentence_score = abs_sentence_score\n",
    "    for word in words:\n",
    "      word_sentiment = sia.polarity_scores(word)\n",
    "      if word_sentiment['compound'] > 0:\n",
    "        positive_words += word + \" \"\n",
    "  else:\n",
    "    sentence_score = abs_sentence_score\n",
    "\n",
    "  return positive_words, negative_words, sentence_score, comment_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2wUCwHSY2uAF"
   },
   "outputs": [],
   "source": [
    "positive_words = \"\"\n",
    "negative_words = \"\"\n",
    "neu_count = 0\n",
    "\n",
    "pos_values_list = []\n",
    "neg_values_list = []\n",
    "avg_pos_score = 0\n",
    "avg_neg_score = 0\n",
    "\n",
    "for comment in comments:\n",
    "  pw, nw, ss, cs = get_comment_sentiment_details(comment)\n",
    "  positive_words += pw+ \" \" #storing pw from each comment into our central positive words\n",
    "  negative_words += nw+ \" \"\n",
    "\n",
    "  if cs == \"NEGATIVE\":\n",
    "    neg_values_list.append(ss)\n",
    "  elif cs == \"POSITIVE\":\n",
    "    pos_values_list.append(ss)\n",
    "  else:\n",
    "    neu_count+=1\n",
    "\n",
    "try:\n",
    "  avg_pos_score = sum(pos_values_list) / len(pos_values_list)\n",
    "  avg_neg_score = sum(neg_values_list) / len(neg_values_list)\n",
    "except ZeroDivisionError:\n",
    "  if len(pos_values_list) == 0 or len(neg_values_list) == 0:\n",
    "    avg_pos_score = 0\n",
    "    avg_neg_score = 0\n",
    "\n",
    "final_score = (avg_pos_score + avg_neg_score) / (len(pos_values_list) + len(neg_values_list))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Lu4APZXT_6or",
    "outputId": "09963405-1f4c-42dd-96d6-aba129d660f3"
   },
   "outputs": [],
   "source": [
    "print(final_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "VIqtTo8D_-td",
    "outputId": "871af969-bce5-4956-8a35-e8559f6906a1"
   },
   "outputs": [],
   "source": [
    "positive_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "yXazFtIiAF9-",
    "outputId": "25f8f248-05dd-4618-8fdd-c28e621eaa0c"
   },
   "outputs": [],
   "source": [
    "negative_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yhr1YznWALkr",
    "outputId": "45ae3ab8-eccc-4627-e215-8cc8cb4fde87"
   },
   "outputs": [],
   "source": [
    "avg_pos_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KLXUctfJAOua",
    "outputId": "6e666bba-d5f3-48e2-f0c6-827959283ec5"
   },
   "outputs": [],
   "source": [
    "avg_neg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dau1rQwmASJf",
    "outputId": "cd21dc53-f2f6-4029-c321-963f0f6230d7"
   },
   "outputs": [],
   "source": [
    "!pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "id": "qPLIrFk7AZ5c",
    "outputId": "154739f3-c09b-4e2f-a1c7-a2607650bb0c"
   },
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"positives\")\n",
    "wordcloud_positive = WordCloud(width=800, height=400, background_color='white').generate(positive_words)\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.imshow(wordcloud_positive, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "id": "BN__1EvCBDPX",
    "outputId": "58f5c864-ab4a-495c-fe10-7ad566e2bd18"
   },
   "outputs": [],
   "source": [
    "print(\"negatives\")\n",
    "wordcloud_negative = WordCloud(width=800, height=400, background_color='white').generate(negative_words)\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.imshow(wordcloud_negative, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nbformat\n",
    "\n",
    "filename = \"Sentiment_Analyzer.ipynb\"  # change to your file name\n",
    "nb = nbformat.read(filename, as_version=nbformat.NO_CONVERT)\n",
    "\n",
    "# Remove metadata.widgets if 'state' is missing\n",
    "if 'widgets' in nb.metadata and 'state' not in nb.metadata['widgets']:\n",
    "    del nb.metadata['widgets']\n",
    "\n",
    "nbformat.write(nb, filename)\n",
    "print(\"Notebook metadata cleaned.\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
